{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import GrayscaleObservation, ResizeObservation, RecordEpisodeStatistics, RecordVideo, TimeLimit\n",
    "from stable_baselines3 import DQN, PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback\n",
    "import os\n",
    "import gc\n",
    "from eval import *\n",
    "from custom_cr import EnhancedCarRacing\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Task Specific Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_rewards(timesteps, results):\n",
    "    # Plot mean rewards over timesteps\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(timesteps, results.mean(axis=1), label=\"Mean Rewards\", color='b')\n",
    "    plt.fill_between(timesteps, results.mean(axis=1) - results.std(axis=1),\n",
    "                    results.mean(axis=1) + results.std(axis=1), color='b', alpha=0.3, label=\"Reward Std Dev\")\n",
    "    plt.xlabel(\"Timesteps\")\n",
    "    plt.ylabel(\"Evaluation Rewards\")\n",
    "    plt.title(\"Evaluation Rewards Over Training Timesteps\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_episode_lengths(timesteps, ep_lengths):# Plot episode lengths over timesteps\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(timesteps, ep_lengths.mean(axis=1), label=\"Mean Episode Lengths\", color='g')\n",
    "    plt.fill_between(timesteps, ep_lengths.mean(axis=1) - ep_lengths.std(axis=1),\n",
    "                    ep_lengths.mean(axis=1) + ep_lengths.std(axis=1), color='g', alpha=0.3, label=\"Episode Length Std Dev\")\n",
    "    plt.xlabel(\"Timesteps\")\n",
    "    plt.ylabel(\"Episode Length\")\n",
    "    plt.title(\"Evaluation Episode Lengths Over Training Timesteps\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1. Baseline DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the evaluations.npz file\n",
    "evaluations = np.load(\"models/baseline/DQN/evaluations.npz\")\n",
    "\n",
    "# List the available keys\n",
    "print(f\"Keys in evaluations.npz: {evaluations.files}\")\n",
    "\n",
    "# Extract relevant data\n",
    "timesteps = evaluations['timesteps']  # Training steps\n",
    "results = evaluations['results']  # Mean rewards (or similar metrics)\n",
    "ep_lengths = evaluations['ep_lengths']  # Episode lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_rewards(timesteps, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_episode_lengths(timesteps, ep_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2. Baseline PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the evaluations.npz file\n",
    "evaluations = np.load(\"models/baseline/PPO/evaluations.npz\")\n",
    "\n",
    "# List the available keys\n",
    "print(f\"Keys in evaluations.npz: {evaluations.files}\")\n",
    "\n",
    "# Extract relevant data\n",
    "timesteps = evaluations['timesteps']  # Training steps\n",
    "results = evaluations['results']  # Mean rewards (or similar metrics)\n",
    "ep_lengths = evaluations['ep_lengths']  # Episode lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_rewards(timesteps, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_episode_lengths(timesteps, ep_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3. Customized DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the evaluations.npz file\n",
    "evaluations = np.load(\"models/custom/DQN/evaluations.npz\")\n",
    "\n",
    "# List the available keys\n",
    "print(f\"Keys in evaluations.npz: {evaluations.files}\")\n",
    "\n",
    "# Extract relevant data\n",
    "timesteps = evaluations['timesteps']  # Training steps\n",
    "results = evaluations['results']  # Mean rewards (or similar metrics)\n",
    "ep_lengths = evaluations['ep_lengths']  # Episode lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_rewards(timesteps, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_episode_lengths(timesteps, ep_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4. Customized PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the evaluations.npz file\n",
    "evaluations = np.load(\"models/custom/PPO/evaluations.npz\")\n",
    "\n",
    "# List the available keys\n",
    "print(f\"Keys in evaluations.npz: {evaluations.files}\")\n",
    "\n",
    "# Extract relevant data\n",
    "timesteps = evaluations['timesteps']  # Training steps\n",
    "results = evaluations['results']  # Mean rewards (or similar metrics)\n",
    "ep_lengths = evaluations['ep_lengths']  # Episode lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_rewards(timesteps, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_episode_lengths(timesteps, ep_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Robustness and Adaptability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Robustness to Observation Noise:\n",
    "   - It runs `num_episodes` episodes with added Gaussian noise to the observations.\n",
    "   - For each step, it adds noise to the observation before predicting an action.\n",
    "   - It accumulates the total reward for each episode and stores it in `noise_rewards`.\n",
    "\n",
    "2. Robustness to Environment Perturbations:\n",
    "   - It runs another set of episodes, this time applying random perturbations to the environment.\n",
    "   - With probability `perturbation_prob`, it adds uniform random noise to the observation.\n",
    "   - It accumulates the total reward for each episode and stores it in `perturbation_rewards`.\n",
    "\n",
    "3. Results Computation and Output:\n",
    "   - For each robustness scenario, it calculates and prints the mean and standard deviation of the rewards.\n",
    "   \n",
    "This function is designed to evaluate how well the trained model performs under different types of perturbations and variations, which is crucial for assessing the robustness and generalization capabilities of the reinforcement learning agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_robustness(model, env, num_episodes=10, noise_std=0.1, perturbation_prob=0.1):\n",
    "    \"\"\"\n",
    "    Evaluate the robustness of a trained model under various challenging conditions.\n",
    "\n",
    "    This function tests the model's ability to handle noisy observations, random perturbations, \n",
    "    and diverse initial states in the environment. Results include performance metrics such as \n",
    "    mean rewards and standard deviations under each condition.\n",
    "\n",
    "    Args:\n",
    "        model (BaseAlgorithm): ThKeysView(NpzFile './best_model/best_model_2.1.1.zip' with keys: data, pytorch_variables.pth, policy.pth, policy.optimizer.pth, _stable_baselines3_version...)e trained model to evaluate. Should support `.predict()` for action selection.\n",
    "        env (gym.Env): The environment in which the model will be tested.\n",
    "        num_episodes (int, optional): The number of episodes to run for each robustness scenario. Defaults to 10.\n",
    "        noise_std (float, optional): Standard deviation of Gaussian noise added to observations. Defaults to 0.1.\n",
    "        perturbation_prob (float, optional): Probability of applying random perturbations to observations. Defaults to 0.1.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with keys:\n",
    "            - \"noise_rewards\": List of total rewards for episodes with noisy observations.\n",
    "            - \"perturbation_rewards\": List of total rewards for episodes with random perturbations.\n",
    "            - \"initial_state_rewards\": List of total rewards for episodes starting from diverse initial states.\n",
    "        Each list includes rewards from `num_episodes` episodes.\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        \"noise_rewards\": [],\n",
    "        \"perturbation_rewards\": []\n",
    "    }\n",
    "    \n",
    "    # Evaluate robustness to observation noise\n",
    "    print(\"Evaluating robustness to observation noise...\")\n",
    "    for _ in range(num_episodes):\n",
    "        print(f\"Running episode {_}\")\n",
    "        obs, _ = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            # Add Gaussian noise to observation\n",
    "            noisy_obs = obs + np.random.normal(0, noise_std, obs.shape)\n",
    "            action = model.predict(noisy_obs, deterministic=True)[0]\n",
    "            obs, reward, done, _, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "        results[\"noise_rewards\"].append(total_reward)\n",
    "        print(f\"Perturbation episode: Total Reward = {total_reward}\")  # For debugging \n",
    "\n",
    "    # Evaluate robustness to environment perturbations\n",
    "    print(\"Evaluating robustness to environment perturbations...\")\n",
    "    for _ in range(num_episodes):\n",
    "        print(f\"Running episode {_}\")\n",
    "        obs, _ = env.reset()\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = model.predict(obs, deterministic=True)[0]\n",
    "            \n",
    "            # Apply random perturbations\n",
    "            if np.random.random() < perturbation_prob:\n",
    "                obs = obs + np.random.uniform(-0.5, 0.5, obs.shape)\n",
    "                \n",
    "            obs, reward, done, _, _ = env.step(action)\n",
    "            total_reward += reward\n",
    "        print(f\"Perturbation episode: Total Reward = {total_reward}\")  # For debugging purposes only, remove in production code.  # Evaluate robustness to environment perturb\n",
    "        results[\"perturbation_rewards\"].append(total_reward)\n",
    "\n",
    "    # Compute and return mean and standard deviation for all scenarios\n",
    "    for key in results:\n",
    "        rewards = np.array(results[key])\n",
    "        print(f\"{key}: Mean = {rewards.mean()}, Std Dev = {rewards.std()}\")\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Baseline - DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_baseline_dqn = DQN.load('./models/baseline/DQN/best_model.zip', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CarRacing-v3\", continuous=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating robustness to observation noise...\n",
      "Running episode 0\n",
      "Perturbation episode: Total Reward = 911.8999999999911\n",
      "Running episode 1\n",
      "Perturbation episode: Total Reward = 919.2999999999857\n",
      "Running episode 2\n",
      "Perturbation episode: Total Reward = 918.4999999999895\n",
      "Running episode 3\n"
     ]
    }
   ],
   "source": [
    "robustness_results_baseline_dqn = evaluate_robustness(best_model_baseline_dqn, env, num_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating robustness to observation noise...\n",
      "Running episode 0\n",
      "Perturbation episode: Total Reward = 914.0999999999913\n",
      "Evaluating robustness to environment perturbations...\n",
      "Running episode 0\n",
      "Perturbation episode: Total Reward = 907.1999999999932\n",
      "noise_rewards: Mean = 914.0999999999913, Std Dev = 0.0\n",
      "perturbation_rewards: Mean = 907.1999999999932, Std Dev = 0.0\n"
     ]
    }
   ],
   "source": [
    "robustness_results_baseline_dqn = evaluate_robustness(best_model_baseline_dqn, env, num_episodes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'noise_rewards': [914.0999999999913],\n",
       " 'perturbation_rewards': [907.1999999999932]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robustness_results_baseline_dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating robustness to observation noise...\n",
      "Running episode 0\n",
      "Perturbation episode: Total Reward = 912.0999999999848\n",
      "Evaluating robustness to environment perturbations...\n",
      "Running episode 0\n",
      "Perturbation episode: Total Reward = 835.899999999969\n",
      "noise_rewards: Mean = 912.0999999999848, Std Dev = 0.0\n",
      "perturbation_rewards: Mean = 835.899999999969, Std Dev = 0.0\n"
     ]
    }
   ],
   "source": [
    "foo = evaluate_robustness(best_model_baseline_dqn, env, num_episodes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustness_results_baseline_dqn['noise_rewards'].append(foo['noise_rewards'])\n",
    "robustness_results_baseline_dqn['perturbation_rewards'].append(foo['perturbation_rewards'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustness_results_baseline_dqn = pd.DataFrame(robustness_results_baseline_dqn)\n",
    "robustness_results_baseline_dqn.to_csv('results/robustness_results_baseline_dqn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noise_rewards</th>\n",
       "      <th>perturbation_rewards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>914.1</td>\n",
       "      <td>907.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>823.0</td>\n",
       "      <td>718.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>844.3</td>\n",
       "      <td>897.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>908.7</td>\n",
       "      <td>916.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>914.0</td>\n",
       "      <td>905.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>912.1</td>\n",
       "      <td>835.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   noise_rewards  perturbation_rewards\n",
       "0          914.1                 907.2\n",
       "1          823.0                 718.9\n",
       "2          844.3                 897.7\n",
       "3          908.7                 916.7\n",
       "4          914.0                 905.1\n",
       "5          912.1                 835.9"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robustness_results_baseline_dqn = pd.read_csv('results/robustness_results_baseline_dqn.csv')\n",
    "robustness_results_baseline_dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_convert(value):\n",
    "    if isinstance(value, str):\n",
    "        value = value.strip('[]')\n",
    "    return float(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_398771/4249244110.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  robustness_results_baseline_dqn = robustness_results_baseline_dqn.applymap(clean_and_convert)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noise_rewards</th>\n",
       "      <th>perturbation_rewards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>914.1</td>\n",
       "      <td>907.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>823.0</td>\n",
       "      <td>718.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>844.3</td>\n",
       "      <td>897.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>908.7</td>\n",
       "      <td>916.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>914.0</td>\n",
       "      <td>905.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>912.1</td>\n",
       "      <td>835.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   noise_rewards  perturbation_rewards\n",
       "0          914.1                 907.2\n",
       "1          823.0                 718.9\n",
       "2          844.3                 897.7\n",
       "3          908.7                 916.7\n",
       "4          914.0                 905.1\n",
       "5          912.1                 835.9"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robustness_results_baseline_dqn = robustness_results_baseline_dqn.applymap(clean_and_convert)\n",
    "robustness_results_baseline_dqn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Baseline - PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Custom Environment - DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_env = EnhancedCarRacing(render_mode=\"rgb_array\")\n",
    "custom_env = GrayscaleObservation(custom_env, keep_dim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W1218 20:29:59.936213148 NNPACK.cpp:61] Could not initialize NNPACK! Reason: Unsupported hardware.\n"
     ]
    }
   ],
   "source": [
    "best_model_custom_dqn = DQN.load('./models/custom/DQN/best_model.zip', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating robustness to observation noise...\n",
      "Running episode 0\n",
      "Perturbation episode: Total Reward = -7759.953796605264\n",
      "Evaluating robustness to environment perturbations...\n",
      "Running episode 0\n",
      "Perturbation episode: Total Reward = -4434.551418120928\n",
      "noise_rewards: Mean = -7759.953796605264, Std Dev = 0.0\n",
      "perturbation_rewards: Mean = -4434.551418120928, Std Dev = 0.0\n"
     ]
    }
   ],
   "source": [
    "robustness_results_custom_dqn = evaluate_robustness(best_model_custom_dqn, custom_env, num_episodes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating robustness to observation noise...\n",
      "Running episode 0\n",
      "Perturbation episode: Total Reward = -7584.80748308475\n",
      "Running episode 1\n",
      "Perturbation episode: Total Reward = -3840.5075875620796\n",
      "Running episode 2\n",
      "Perturbation episode: Total Reward = -7460.315858936726\n",
      "Running episode 3\n",
      "Perturbation episode: Total Reward = -7861.306102609049\n",
      "Running episode 4\n",
      "Perturbation episode: Total Reward = -7541.33890571855\n",
      "Evaluating robustness to environment perturbations...\n",
      "Running episode 0\n",
      "Perturbation episode: Total Reward = -7514.179581865233\n",
      "Running episode 1\n",
      "Perturbation episode: Total Reward = -3519.7626820016026\n",
      "Running episode 2\n",
      "Perturbation episode: Total Reward = -7947.5827114948215\n",
      "Running episode 3\n",
      "Perturbation episode: Total Reward = -9068.230437492533\n",
      "Running episode 4\n",
      "Perturbation episode: Total Reward = -4008.980884820603\n",
      "noise_rewards: Mean = -6857.655187582231, Std Dev = 1514.5869781322078\n",
      "perturbation_rewards: Mean = -6411.747259534958, Std Dev = 2225.664461851139\n"
     ]
    }
   ],
   "source": [
    "foo = evaluate_robustness(best_model_custom_dqn, custom_env, num_episodes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustness_results_custom_dqn['noise_rewards'].append(foo['noise_rewards'])\n",
    "robustness_results_custom_dqn['perturbation_rewards'].append(foo['perturbation_rewards'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'noise_rewards': [-7759.953796605264,\n",
       "  [-7858.43471366518],\n",
       "  [-4357.975981461611],\n",
       "  [-7663.295497849881],\n",
       "  [-8118.9301815847275],\n",
       "  [-7584.80748308475,\n",
       "   -3840.5075875620796,\n",
       "   -7460.315858936726,\n",
       "   -7861.306102609049,\n",
       "   -7541.33890571855]],\n",
       " 'perturbation_rewards': [-4434.551418120928,\n",
       "  [-7241.206349396435],\n",
       "  [-7743.716855095754],\n",
       "  [-7901.444085518807],\n",
       "  [-7828.554151708476],\n",
       "  [-7514.179581865233,\n",
       "   -3519.7626820016026,\n",
       "   -7947.5827114948215,\n",
       "   -9068.230437492533,\n",
       "   -4008.980884820603]]}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robustness_results_custom_dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noise_rewards</th>\n",
       "      <th>perturbation_rewards</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-7759.953796605264</td>\n",
       "      <td>-4434.551418120928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-7858.43471366518]</td>\n",
       "      <td>[-7241.206349396435]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-4357.975981461611]</td>\n",
       "      <td>[-7743.716855095754]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-7663.295497849881]</td>\n",
       "      <td>[-7901.444085518807]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-8118.9301815847275]</td>\n",
       "      <td>[-7828.554151708476]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-7584.80748308475, -3840.5075875620796, -7460...</td>\n",
       "      <td>[-7514.179581865233, -3519.7626820016026, -794...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       noise_rewards  \\\n",
       "0                                 -7759.953796605264   \n",
       "1                                [-7858.43471366518]   \n",
       "2                               [-4357.975981461611]   \n",
       "3                               [-7663.295497849881]   \n",
       "4                              [-8118.9301815847275]   \n",
       "5  [-7584.80748308475, -3840.5075875620796, -7460...   \n",
       "\n",
       "                                perturbation_rewards  \n",
       "0                                 -4434.551418120928  \n",
       "1                               [-7241.206349396435]  \n",
       "2                               [-7743.716855095754]  \n",
       "3                               [-7901.444085518807]  \n",
       "4                               [-7828.554151708476]  \n",
       "5  [-7514.179581865233, -3519.7626820016026, -794...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robustness_results_custom_dqn = pd.DataFrame(robustness_results_custom_dqn)\n",
    "robustness_results_custom_dqn.to_csv('results/robustness_results_custom_dqn.csv', index=False)\n",
    "robustness_results_custom_dqn = pd.read_csv('results/robustness_results_custom_dqn.csv')\n",
    "robustness_results_custom_dqn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Custom Environment - PPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated or pre-loaded CSV paths\n",
    "# Replace these with your actual file paths\n",
    "baseline_dqn = pd.read_csv('results/robustness_results_baseline_dqn.csv')\n",
    "baseline_ppo = pd.read_csv('results/robustness_results_baseline_ppo.csv')\n",
    "custom_dqn = pd.read_csv('results/robustness_results_custom_dqn.csv')\n",
    "custom_ppo = pd.read_csv('results/robustness_results_custom_ppo.csv')\n",
    "\n",
    "# Calculate the mean of rewards for each model\n",
    "noise_means = {\n",
    "    \"Baseline DQN\": baseline_dqn[\"noise_rewards\"].mean(),\n",
    "    \"Baseline PPO\": baseline_ppo[\"noise_rewards\"].mean(),\n",
    "    \"Custom DQN\": custom_dqn[\"noise_rewards\"].mean(),\n",
    "    \"Custom PPO\": custom_ppo[\"noise_rewards\"].mean(),\n",
    "}\n",
    "\n",
    "perturbation_means = {\n",
    "    \"Baseline DQN\": baseline_dqn[\"perturbation_rewards\"].mean(),\n",
    "    \"Baseline PPO\": baseline_ppo[\"perturbation_rewards\"].mean(),\n",
    "    \"Custom DQN\": custom_dqn[\"perturbation_rewards\"].mean(),\n",
    "    \"Custom PPO\": custom_ppo[\"perturbation_rewards\"].mean(),\n",
    "}\n",
    "\n",
    "# Plot histogram for noise rewards\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(noise_means.keys(), noise_means.values(), color=['blue', 'green', 'orange', 'red'])\n",
    "plt.title(\"Comparison of Mean Noise Rewards\")\n",
    "plt.ylabel(\"Mean Noise Reward\")\n",
    "plt.xlabel(\"Models\")\n",
    "plt.show()\n",
    "\n",
    "# Plot histogram for perturbation rewards\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(perturbation_means.keys(), perturbation_means.values(), color=['blue', 'green', 'orange', 'red'])\n",
    "plt.title(\"Comparison of Mean Perturbation Rewards\")\n",
    "plt.ylabel(\"Mean Perturbation Reward\")\n",
    "plt.xlabel(\"Models\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
